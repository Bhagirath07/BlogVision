# #65 Machine Learning & Data Science Challenge 65

# What is the Evolution technique of CNN?

* It all started with LeNet in 1998 and eventually, after nearly 15 years, lead to groundbreaking models winning the ImageNet Large-Scale Visual Recognition Challenge which includes AlexNet in 2012, Google Net in 2014, and ResNet in 2015, an ensemble of previous models in 2016.
    
* In the last two years, no significant progress has been made, and the new models are an ensemble of previous groundbreaking models.
    

> ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1673622074715/68874ca9-d369-431d-b461-2d69e56d196f.png align="center")

### LeNet in 1998:

* LeNet is a 7-level convolutional network by LeCun in 1998 that classifies digits and is used by several banks to recognize the hand-written numbers on cheques digitized in 32x32 pixel greyscale input images.
    

### AlexNet in 2012:

* AlexNet is considered to be the first paper/ model, which rose the interest of CNNs when it won the ImageNet challenge in the year 2012. It is a deep CNN trained on ImageNet and outperformed all the entries that year.
    

### VGG in 2014:

* VGG was submitted in the year 2013, and it became a runner-up in the ImageNet contest in 2014. It is widely used as a simple architecture compared to AlexNet.
    

### GoogleNet in 2014:

* In 2014, several great models were developed like VGG, but the winner of the ImageNet contest was GoogleNet.
    
* GoogleNet proposed a module called the inception module that includes skipping connections in the network and forming a mini-module, and this module is repeated throughout the network.
    

### ResNet in 2015:

* There are 152 layers in the Microsoft ResNet. The authors showed empirically that if you keep on adding layers, the error rate should keep on decreasing in contrast to “plain nets” we're adding a few layers resulted in higher training and test errors.