# #73 Machine Learning & Data Science Challenge 73

# Why do we need Non-linear activation functions?

**A neural network without activation functions is essentially a linear regression model. The activation functions do the non-linear transformation to the input, making it capable of learning and performing more complex tasks.**

1. Identity
    
2. Binary Step
    
3. Sigmoid
    
4. Tanh
    
5. ReLU
    
6. Leaky ReLU
    
7. Softmax
    

* The activation functions do the non-linear transformation to the input, making it capable of learning and performing more complex tasks.